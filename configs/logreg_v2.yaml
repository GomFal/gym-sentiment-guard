# LogReg V2 Model Configuration
# Best model from ablation suite (run.2026-01-07_392)
# Winner: F1_neg=0.901, Recall_neg=0.906, Macro F1=0.936

model:
  name: sentiment_logreg
  type: logistic_regression
  version: v2

data:
  splits:
    train: data/frozen/sentiment_logreg/2025.12.15_01/train/train.csv
    val:   data/frozen/sentiment_logreg/2025.12.15_01/val/val.csv
    test:  data/frozen/sentiment_logreg/2025.12.15_01/test/test.csv

  text_column: comment
  label_column: sentiment

  label_mapping:
    negative: 0
    positive: 1


vectorizer:
  type: tfidf
  lowercase: true
  ngram_range: [1, 3]      # Updated: trigrams for better context
  min_df: 10               # Updated: aggressive pruning
  max_df: 0.90             # Updated: removes very common terms
  sublinear_tf: true


classifier:
  type: logistic_regression
  max_iter: 1000
  C: 5.0                   # Updated: less regularization
  solver: lbfgs
  n_jobs: -1
  class_weight: balanced   # Updated: class balancing


calibration:
  enabled: true
  method: isotonic
  cv: 5
  random_state: 42


decision:
  threshold: 0.477         # Updated: optimized on VAL
  target_class: negative


runtime:
  python_version: "3.12.4"
  sklearn_version: "1.7.2"
  numpy_version: "2.3.4"

git:
  commit: 2e17092ad0469513aeebbd16c42716be4a5f9b3b
  branch: main
  dirty: true


artifacts:
  output_dir: artifacts/models/sentiment_logreg
  format: joblib


# Provenance
experiment:
  source_run: run.2026-01-07_392
  suite: suite.2026-01-07_235051
  val_metrics:
    f1_neg: 0.901
    recall_neg: 0.906
    precision_neg: 0.897
    macro_f1: 0.936
    pr_auc_neg: 0.946
